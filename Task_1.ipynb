{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUFflvhkk9WsaCqqSi5tTY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishnu75678/R-D-INFRO-TECHNOLOGY/blob/main/Task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMABNT-asMW-",
        "outputId": "1093c1f5-5776-4046-c79e-0c42a60a0b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Head:\n",
            "    PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "Dataset Info:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            " PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "\n",
            "Processed Data Head:\n",
            "         Age      Fare     SibSp     Parch  Sex_male  Embarked_Q  Embarked_S  \\\n",
            "0 -0.565736 -0.502445  0.432793 -0.473674       1.0         0.0         1.0   \n",
            "1  0.663861  0.786845  0.432793 -0.473674       0.0         0.0         0.0   \n",
            "2 -0.258337 -0.488854 -0.474545 -0.473674       0.0         0.0         1.0   \n",
            "3  0.433312  0.420730  0.432793 -0.473674       0.0         0.0         1.0   \n",
            "4  0.433312 -0.486337 -0.474545 -0.473674       1.0         0.0         1.0   \n",
            "\n",
            "   Pclass_2  Pclass_3  \n",
            "0       0.0       1.0  \n",
            "1       0.0       0.0  \n",
            "2       0.0       1.0  \n",
            "3       0.0       0.0  \n",
            "4       0.0       1.0  \n",
            "\n",
            "Final Processed Data Head:\n",
            "         Age      Fare     SibSp     Parch  Sex_male  Embarked_Q  Embarked_S  \\\n",
            "0 -0.565736 -0.502445  0.432793 -0.473674       1.0         0.0         1.0   \n",
            "1  0.663861  0.786845  0.432793 -0.473674       0.0         0.0         0.0   \n",
            "2 -0.258337 -0.488854 -0.474545 -0.473674       0.0         0.0         1.0   \n",
            "3  0.433312  0.420730  0.432793 -0.473674       0.0         0.0         1.0   \n",
            "4  0.433312 -0.486337 -0.474545 -0.473674       1.0         0.0         1.0   \n",
            "\n",
            "   Pclass_2  Pclass_3  Survived  \n",
            "0       0.0       1.0         0  \n",
            "1       0.0       0.0         1  \n",
            "2       0.0       1.0         1  \n",
            "3       0.0       0.0         1  \n",
            "4       0.0       1.0         0  \n",
            "\n",
            "Data Cleaning and Preprocessing Completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-23ce2a41b7f0>:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-1-23ce2a41b7f0>:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Display basic information\n",
        "print(\"Dataset Head:\\n\", data.head())\n",
        "print(\"\\nDataset Info:\\n\")\n",
        "print(data.info())\n",
        "print(\"\\nMissing Values:\\n\", data.isnull().sum())\n",
        "\n",
        "# Step 1: Handling Missing Values\n",
        "# Fill missing 'Age' with median\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "\n",
        "# Fill missing 'Embarked' with the most frequent value\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop 'Cabin' column due to a large number of missing values\n",
        "data.drop(columns=['Cabin'], inplace=True)\n",
        "\n",
        "# Step 2: Converting Categorical Variables (One-Hot Encoding)\n",
        "categorical_features = ['Sex', 'Embarked', 'Pclass']\n",
        "numerical_features = ['Age', 'Fare', 'SibSp', 'Parch']\n",
        "\n",
        "# Create Column Transformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),          # Standardize numerical features\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical_features) # One-Hot Encode categorical features\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply the transformations to the data\n",
        "processed_data = preprocessor.fit_transform(data[numerical_features + categorical_features])\n",
        "\n",
        "# Convert processed data to DataFrame with meaningful column names\n",
        "processed_data = pd.DataFrame(processed_data, columns=[\n",
        "    'Age', 'Fare', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S', 'Pclass_2', 'Pclass_3'\n",
        "])\n",
        "\n",
        "print(\"\\nProcessed Data Head:\\n\", processed_data.head())\n",
        "\n",
        "# Combine processed features with the target variable (if available)\n",
        "if 'Survived' in data.columns:\n",
        "    final_data = pd.concat([processed_data, data['Survived']], axis=1)\n",
        "    print(\"\\nFinal Processed Data Head:\\n\", final_data.head())\n",
        "else:\n",
        "    final_data = processed_data\n",
        "\n",
        "# Save the cleaned and preprocessed data\n",
        "final_data.to_csv('cleaned_customer_churn.csv', index=False)\n",
        "print(\"\\nData Cleaning and Preprocessing Completed!\")"
      ]
    }
  ]
}